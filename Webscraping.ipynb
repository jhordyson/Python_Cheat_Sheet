{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea99653f-daf7-4d85-9b0c-389c96c82c19",
   "metadata": {},
   "source": [
    "# Working with web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988279cb-d3f2-47c0-9437-d5d4de20c080",
   "metadata": {},
   "source": [
    "### 1. Fetching web pages with requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190136be-43bd-40ac-859d-db2fd35106c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://example.com'\n",
    "response = requests.get(url)\n",
    "html = response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd23999f-a628-4078-93b9-3c14bbb532f4",
   "metadata": {},
   "source": [
    "### 2. Parsing html with beautifulsoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd32289f-89d6-41fe-871e-a7a780d051e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "print(soup.prettify())  # Pretty-print the HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e53bb3-6ede-4a97-884a-9a2a787b47b1",
   "metadata": {},
   "source": [
    "### 3. Navigating the html tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e557f1-5845-4ac5-af4a-81416234fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = soup.title.text  # Get the page title\n",
    "headings = soup.find_all('h1')  # List of all <h1> tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f90332f-2640-4812-8e0e-2504388a9b75",
   "metadata": {},
   "source": [
    "### 4. Using css selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bf30ca-ba5b-492e-89dd-157a40fea49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = soup.select('div.article')  # All elements with class 'article' inside a <div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063aaf95-17c2-4796-8063-93546bfdb157",
   "metadata": {},
   "source": [
    "### 5. Extracting data from tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb94356-bb4a-43ab-8910-ea94b84bb131",
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in articles:\n",
    "    title = article.h2.text  # Text inside the <h2> tag\n",
    "    link = article.a['href']  # 'href' attribute of the <a> tag\n",
    "    print(title, link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87914087-c492-4929-95c0-8e64eb8ddf1d",
   "metadata": {},
   "source": [
    "### 6. Handling relative urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f89ff4c-2296-4eb8-ad18-389ffc260997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urljoin\n",
    "absolute_urls = [urljoin(url, link) for link in relative_urls]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1d4c4b-2550-47b2-b913-fa5b404d66ed",
   "metadata": {},
   "source": [
    "### 7. To scrape content across multiple pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a768b2b0-db8c-4fa0-8979-f89383113aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://example.com/page/\"\n",
    "for page in range(1, 6):  # For 5 pages\n",
    "    page_url = base_url + str(page)\n",
    "    response = requests.get(page_url)\n",
    "    # Process each page's content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff58d9b-2d63-4ca4-9ece-0962f7cdda42",
   "metadata": {},
   "source": [
    "### 8. To scrape data by ajax requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a01caa6-06be-4763-8c05-1d3a27e02b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the URL of the AJAX request (using browser's developer tools) and fetch it\n",
    "ajax_url = 'https://example.com/ajax_endpoint'\n",
    "data = requests.get(ajax_url).json()  # Assuming the response is JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae46c9e-175d-47b3-beff-2edace74db96",
   "metadata": {},
   "source": [
    "### 9. Using regex in web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810bed8f-969f-48d2-a3b2-e3ad62fb591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "emails = re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6ef397-28d0-4675-8cfe-9237829ddb3c",
   "metadata": {},
   "source": [
    "### 10. To check robots.txt for scraping permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88075576-5fb8-4dff-a630-c2c5ed8fef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.robotparser import RobotFileParser\n",
    "\n",
    "rp = RobotFileParser()\n",
    "rp.set_url('https://example.com/robots.txt')\n",
    "rp.read()\n",
    "can_scrape = rp.can_fetch('*', url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dc2bab-016c-4bc7-8c1b-c9f64a8a2973",
   "metadata": {},
   "source": [
    "### 11. Using sessions and cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce8741c-dff9-4dea-80a7-e460d897ab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "session.get('https://example.com/login')\n",
    "session.cookies.set('key', 'value')  # Set cookies, if needed\n",
    "response = session.get('https://example.com/protected_page')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0b9ce4-4373-4691-aaaa-cdc0d04fd92d",
   "metadata": {},
   "source": [
    "### 12. Scraping with browser automation (selenium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c13659d-b2b2-4704-a85b-1db2b1ba0ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "browser = webdriver.Chrome()\n",
    "browser.get('https://example.com')\n",
    "content = browser.page_source\n",
    "# Parse and extract data using BeautifulSoup, etc.\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f908ef-9dc1-4109-b68f-4507e3b8b810",
   "metadata": {},
   "source": [
    "### 13. Error handling in web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70231d4e-c646-4bcd-be5b-927b71cd2263",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = requests.get(url, timeout=5)\n",
    "    response.raise_for_status()  # Raises an error for bad status codes\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf41c1b0-c698-4ff6-b6b5-cb5bed85aca7",
   "metadata": {},
   "source": [
    "### 14. Asynchronous web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a93142-26da-4372-b7ad-3246764443a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "async def fetch(url):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(url) as response:\n",
    "            return await response.text()\n",
    "\n",
    "urls = ['https://example.com/page1', 'https://example.com/page2']\n",
    "loop = asyncio.get_event_loop()\n",
    "pages = loop.run_until_complete(asyncio.gather(*(fetch(url) for url in urls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6177800c-d814-4395-90b2-2e0b2bdb2c38",
   "metadata": {},
   "source": [
    "### 15. Data storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5646f6d-68f5-4cd6-8a12-8d3566034114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('output.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Title', 'URL'])\n",
    "    for article in articles:\n",
    "        writer.writerow([article['title'], article['url']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
